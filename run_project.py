#!/usr/bin/env python3
"""
ğŸŒ± Script Principal - DetecÃ§Ã£o de DoenÃ§as em Plantas

Este script executa todo o pipeline do projeto:
1. PreparaÃ§Ã£o dos dados
2. Treinamento dos modelos
3. ComparaÃ§Ã£o de performance
4. VisualizaÃ§Ã£o com GradCAM

Uso:
    python run_project.py --mode all          # Executa tudo
    python run_project.py --mode train        # Apenas treinamento
    python run_project.py --mode compare      # Apenas comparaÃ§Ã£o
    python run_project.py --mode gradcam      # Apenas GradCAM
"""

import argparse
import os
import sys
import time
from pathlib import Path

def check_dependencies():
    """Verifica se todas as dependÃªncias estÃ£o instaladas"""
    print("ğŸ” Verificando dependÃªncias...")

    required_packages = [
        'torch', 'torchvision', 'transformers', 'datasets',
        'PIL', 'numpy', 'matplotlib', 'seaborn', 'sklearn',
        'cv2', 'tqdm'
    ]

    missing_packages = []

    for package in required_packages:
        try:
            __import__(package)
            print(f"   âœ… {package}")
        except ImportError:
            missing_packages.append(package)
            print(f"   âŒ {package}")

    if missing_packages:
        print(f"\nâŒ Pacotes faltando: {', '.join(missing_packages)}")
        print("   Execute: pip install -r requirements.txt")
        return False

    print("âœ… Todas as dependÃªncias estÃ£o instaladas!")
    return True

def check_dataset():
    """Verifica se o dataset estÃ¡ disponÃ­vel"""
    print("\nğŸ“Š Verificando dataset...")

    data_dir = Path("data")
    required_folders = ["train", "valid", "test"]

    if not data_dir.exists():
        print("   âŒ Pasta 'data/' nÃ£o encontrada")
        print("   ğŸ“¥ Baixe o dataset do Kaggle primeiro")
        return False

    missing_folders = []
    for folder in required_folders:
        folder_path = data_dir / folder
        if not folder_path.exists():
            missing_folders.append(folder)
            print(f"   âŒ Pasta '{folder}/' nÃ£o encontrada")
        else:
            # Verificar se tem subpastas (classes)
            subfolders = [f for f in folder_path.iterdir() if f.is_dir()]
            if len(subfolders) == 0:
                print(f"   âš ï¸  Pasta '{folder}/' estÃ¡ vazia")
            else:
                print(f"   âœ… {folder}/ ({len(subfolders)} classes)")

    if missing_folders:
        print(f"\nâŒ Pastas faltando: {', '.join(missing_folders)}")
        return False

    print("âœ… Dataset verificado com sucesso!")
    return True

def run_data_preparation():
    """Executa a preparaÃ§Ã£o dos dados"""
    print("\nğŸ“Š Executando preparaÃ§Ã£o dos dados...")

    try:
        sys.path.append('src')
        from data_preparation import get_data_loaders

        # Testar carregamento
        train_loader, val_loader, classes = get_data_loaders(
            "data",
            batch_size=4,
            num_workers=2
        )

        print(f"   âœ… Dados carregados: {len(classes)} classes")
        print(f"   ğŸ“š Treinamento: {len(train_loader.dataset)} amostras")
        print(f"   âœ… ValidaÃ§Ã£o: {len(val_loader.dataset)} amostras")

        return True

    except Exception as e:
        print(f"   âŒ Erro na preparaÃ§Ã£o dos dados: {e}")
        return False

def run_training():
    """Executa o treinamento dos modelos"""
    print("\nğŸš€ Executando treinamento dos modelos...")

    try:
        # Verificar se jÃ¡ existem modelos treinados
        models_dir = Path("models")
        if models_dir.exists():
            existing_models = list(models_dir.glob("best_*.pth"))
            if existing_models:
                print("   âš ï¸  Modelos treinados jÃ¡ existem:")
                for model in existing_models:
                    print(f"      - {model.name}")

                response = input("   ğŸ”„ Deseja sobrescrever? (y/N): ").lower()
                if response != 'y':
                    print("   â­ï¸  Pulando treinamento...")
                    return True

        # Executar treinamento
        from src.train import main as train_main
        train_main()

        return True

    except Exception as e:
        print(f"   âŒ Erro no treinamento: {e}")
        return False

def run_comparison():
    """Executa a comparaÃ§Ã£o dos modelos"""
    print("\nğŸ“ˆ Executando comparaÃ§Ã£o dos modelos...")

    try:
        # Verificar se existem modelos treinados
        models_dir = Path("models")
        if not models_dir.exists():
            print("   âŒ Pasta 'models/' nÃ£o encontrada")
            print("   ğŸš€ Execute o treinamento primeiro")
            return False

        existing_models = list(models_dir.glob("best_*.pth"))
        if not existing_models:
            print("   âŒ Nenhum modelo treinado encontrado")
            print("   ğŸš€ Execute o treinamento primeiro")
            return False

        print(f"   âœ… {len(existing_models)} modelos encontrados")

        # Executar comparaÃ§Ã£o
        from src.model_comparison import main as compare_main
        compare_main()

        return True

    except Exception as e:
        print(f"   âŒ Erro na comparaÃ§Ã£o: {e}")
        return False

def run_gradcam():
    """Executa a visualizaÃ§Ã£o com GradCAM"""
    print("\nğŸ” Executando visualizaÃ§Ã£o com GradCAM...")

    try:
        # Verificar se existem modelos treinados
        models_dir = Path("models")
        if not models_dir.exists():
            print("   âŒ Pasta 'models/' nÃ£o encontrada")
            print("   ğŸš€ Execute o treinamento primeiro")
            return False

        existing_models = list(models_dir.glob("best_*.pth"))
        if not existing_models:
            print("   âŒ Nenhum modelo treinado encontrado")
            print("   ğŸš€ Execute o treinamento primeiro")
            return False

        print(f"   âœ… {len(existing_models)} modelos encontrados")

        # Executar GradCAM
        from src.gradcam import main as gradcam_main
        gradcam_main()

        return True

    except Exception as e:
        print(f"   âŒ Erro no GradCAM: {e}")
        return False

def run_notebook():
    """Abre o notebook Jupyter"""
    print("\nğŸ““ Abrindo notebook Jupyter...")

    notebook_path = Path("notebooks/plant_disease_detection.ipynb")
    if not notebook_path.exists():
        print("   âŒ Notebook nÃ£o encontrado")
        return False

    try:
        import subprocess
        subprocess.run(["jupyter", "notebook", str(notebook_path)])
        return True
    except Exception as e:
        print(f"   âŒ Erro ao abrir notebook: {e}")
        print("   ğŸ’¡ Execute manualmente: jupyter notebook notebooks/plant_disease_detection.ipynb")
        return False

def main():
    """FunÃ§Ã£o principal"""
    parser = argparse.ArgumentParser(
        description="ğŸŒ± Script Principal - DetecÃ§Ã£o de DoenÃ§as em Plantas",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python run_project.py --mode all          # Executa todo o pipeline
  python run_project.py --mode train        # Apenas treinamento
  python run_project.py --mode compare      # Apenas comparaÃ§Ã£o
  python run_project.py --mode gradcam      # Apenas GradCAM
  python run_project.py --mode notebook     # Abre o notebook
        """
    )

    parser.add_argument(
        '--mode',
        choices=['all', 'train', 'compare', 'gradcam', 'notebook'],
        default='all',
        help='Modo de execuÃ§Ã£o (padrÃ£o: all)'
    )

    parser.add_argument(
        '--skip-checks',
        action='store_true',
        help='Pular verificaÃ§Ãµes de dependÃªncias e dataset'
    )

    args = parser.parse_args()

    print("ğŸŒ±" + "="*60)
    print("   DETECÃ‡ÃƒO DE DOENÃ‡AS EM PLANTAS - PIPELINE COMPLETO")
    print("="*60)

    start_time = time.time()

    # VerificaÃ§Ãµes iniciais
    if not args.skip_checks:
        if not check_dependencies():
            sys.exit(1)

        if not check_dataset():
            print("\nâŒ Dataset nÃ£o encontrado ou incompleto")
            print("ğŸ“¥ Baixe o dataset do Kaggle primeiro:")
            print("   https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset")
            sys.exit(1)

    # Executar pipeline baseado no modo
    success = True

    if args.mode in ['all', 'train']:
        if not run_data_preparation():
            success = False
        elif not run_training():
            success = False

    if args.mode in ['all', 'compare'] and success:
        if not run_comparison():
            success = False

    if args.mode in ['all', 'gradcam'] and success:
        if not run_gradcam():
            success = False

    if args.mode == 'notebook':
        run_notebook()

    # Resumo final
    end_time = time.time()
    duration = end_time - start_time

    print("\n" + "="*60)
    if success:
        print("ğŸ‰ PIPELINE EXECUTADO COM SUCESSO!")
        print(f"â±ï¸  Tempo total: {duration:.1f} segundos")

        if args.mode == 'all':
            print("\nğŸ“ Arquivos gerados:")
            print("   ğŸ“‚ models/ - Modelos treinados")
            print("   ğŸ“‚ model_comparison/ - Resultados da comparaÃ§Ã£o")
            print("   ğŸ“‚ gradcam_results/ - VisualizaÃ§Ãµes do GradCAM")
            print("\nğŸ’¡ PrÃ³ximos passos:")
            print("   ğŸ““ Abra o notebook: python run_project.py --mode notebook")
            print("   ğŸ” Analise os resultados em model_comparison/")
            print("   ğŸ“Š Visualize as curvas de treinamento em models/")
    else:
        print("âŒ PIPELINE FALHOU!")
        print("ğŸ” Verifique os erros acima e tente novamente")

    print("="*60)

if __name__ == "__main__":
    main()
